import streamlit as st
import cv2
import tempfile
from ultralytics import YOLO
import numpy as np
import av
import time
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLO11 äººä½“å§¿æ€ä¼°è®¡ (å®æ—¶æµç‰ˆ)",
    page_icon="ğŸ‘¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- å…¨å±€è®¾ç½®å’Œæ¨¡å‹åŠ è½½ ---

# åŠ è½½ YOLO11 å§¿æ€æ¨¡å‹
@st.cache_resource
def load_model():
    """åŠ è½½ YOLO11 å§¿æ€æ¨¡å‹"""
    try:
        model = YOLO('yolo11n-pose.pt')
        st.success("âœ… YOLO11 å§¿æ€æ¨¡å‹å·²åœ¨äº‘ç«¯æˆåŠŸåŠ è½½ï¼")
        return model
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

model = load_model()

# --- æ ¸å¿ƒå¤„ç†é€»è¾‘ (ç”¨äº WebRTC) ---

class PoseDetectionTransformer(VideoTransformerBase):
    """
    è‡ªå®šä¹‰çš„è§†é¢‘æµå¤„ç†å™¨ã€‚
    æ¯æ”¶åˆ°ä¸€å¸§è§†é¢‘ï¼Œå°±ä¼šè°ƒç”¨ transform æ–¹æ³•è¿›è¡Œå¤„ç†ã€‚
    """
    def __init__(self):
        self.conf_threshold = 0.5 # é»˜è®¤ç½®ä¿¡åº¦

    def set_conf_threshold(self, conf):
        """æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼"""
        self.conf_threshold = conf

    def transform(self, frame):
        """
        å¤„ç†å•å¸§å›¾åƒçš„æ ¸å¿ƒæ–¹æ³•ã€‚
        frame: è¾“å…¥çš„è§†é¢‘å¸§ (av.VideoFrame å¯¹è±¡)
        è¿”å›: å¤„ç†åçš„è§†é¢‘å¸§ (av.VideoFrame å¯¹è±¡)
        """
        if model is None:
            return frame

        # 1. å°† av.VideoFrame è½¬æ¢ä¸º numpy æ•°ç»„ (BGR æ ¼å¼)
        img = frame.to_ndarray(format="bgr24")

        # 2. ä½¿ç”¨ YOLO æ¨¡å‹è¿›è¡Œå§¿æ€ä¼°è®¡
        results = model(img, conf=self.conf_threshold)

        # 3. åœ¨åŸå§‹å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
        annotated_img = results[0].plot()

        # 4. å°†å¤„ç†åçš„ numpy æ•°ç»„è½¬æ¢å› av.VideoFrame
        return av.VideoFrame.from_ndarray(annotated_img, format="bgr24")

# --- UI å¸ƒå±€ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.title('ğŸ‘¤ YOLO11 äººä½“å§¿æ€ä¼°è®¡')
    st.markdown("""
    è¿™ä¸ªåº”ç”¨åœ¨**äº‘ç«¯**è¿è¡Œï¼Œä½¿ç”¨**æ‚¨æœ¬åœ°ç”µè„‘çš„æ‘„åƒå¤´**è¿›è¡Œ**å®æ—¶**äººä½“å§¿æ€ä¼°è®¡ã€‚
    è¯·é€‰æ‹©è¾“å…¥æºå¼€å§‹ã€‚
    """)
    st.divider()

    source = st.selectbox("è¯·é€‰æ‹©è¾“å…¥æº", ["å›¾ç‰‡", "è§†é¢‘", "æ‘„åƒå¤´ (å®æ—¶æµ)"])
    
    # åˆå§‹åŒ– session_state
    if 'conf_threshold' not in st.session_state:
        st.session_state.conf_threshold = 0.5
    
    # ç½®ä¿¡åº¦æ»‘å—
    conf_threshold = st.slider("æ£€æµ‹ç½®ä¿¡åº¦", 0.0, 1.0, st.session_state.conf_threshold, 0.05)
    
    st.divider()
    st.markdown("Â© 2024 Streamlit & YOLO11")

# ä¸»é¡µé¢
st.title("YOLO11 äººä½“å§¿æ€ä¼°è®¡æ¼”ç¤º (å®æ—¶æµç‰ˆ)")

if model is not None:
    if source == "å›¾ç‰‡":
        st.subheader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œå§¿æ€ä¼°è®¡")
        uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            col1, col2 = st.columns(2)
            with col1:
                st.markdown("### åŸå§‹å›¾ç‰‡")
                st.image(uploaded_file, use_column_width=True)
            with col2:
                st.markdown("### å§¿æ€ä¼°è®¡ç»“æœ")
                if st.button("å¼€å§‹æ£€æµ‹"):
                    with st.spinner("æ­£åœ¨äº‘ç«¯æ£€æµ‹å§¿æ€..."):
                        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                        img = cv2.imdecode(file_bytes, 1)
                        results = model(img, conf=conf_threshold)
                        annotated_img = results[0].plot()
                        st.image(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB), use_column_width=True)

    elif source == "è§†é¢‘":
        st.subheader("ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è¿›è¡Œå§¿æ€ä¼°è®¡")
        uploaded_file = st.file_uploader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘", type=["mp4", "mov", "avi", "mkv"])
        
        if uploaded_file is not None:
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(uploaded_file.read())
            
            cap = cv2.VideoCapture(tfile.name)
            if not cap.isOpened():
                st.error("âŒ æ— æ³•æ‰“å¼€ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶ã€‚")
            else:
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                
                st.write(f"ğŸ“Š è§†é¢‘å±æ€§: {width}x{height}, {fps} FPS, æ€»å¸§æ•°: {total_frames}")
                
                if st.button("å¼€å§‹åœ¨äº‘ç«¯å¤„ç†è§†é¢‘"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    output_filename = "output_video.mp4"
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    out = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))
                    
                    with st.spinner("ğŸ¬ æ­£åœ¨äº‘ç«¯å¤„ç†è§†é¢‘ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                        for frame_count in range(total_frames):
                            ret, frame = cap.read()
                            if not ret:
                                break
                                
                            results = model(frame, conf=conf_threshold)
                            annotated_frame = results[0].plot()
                            out.write(annotated_frame)
                            
                            progress = (frame_count + 1) / total_frames
                            progress_bar.progress(progress)
                            status_text.text(f"å¤„ç†è¿›åº¦: {frame_count + 1}/{total_frames} ({progress:.1%})")
                    
                    cap.release()
                    out.release()
                    progress_bar.empty()
                    status_text.empty()
                    
                    st.success("âœ… è§†é¢‘å¤„ç†å®Œæˆï¼")
                    
                    with open(output_filename, 'rb') as f:
                        st.download_button(
                            label='ğŸ“¥ ä¸‹è½½å¤„ç†åçš„è§†é¢‘',
                            data=f,
                            file_name=output_filename,
                            mime='video/mp4'
                        )

    elif source == "æ‘„åƒå¤´ (å®æ—¶æµ)":
        st.subheader("ä½¿ç”¨æ‚¨çš„æœ¬åœ°æ‘„åƒå¤´è¿›è¡Œå®æ—¶å§¿æ€ä¼°è®¡")
        st.markdown("""
        è¯·å…è®¸æµè§ˆå™¨è®¿é—®æ‚¨çš„æ‘„åƒå¤´ã€‚åº”ç”¨ä¼šå°†æ‚¨çš„æ‘„åƒå¤´ç”»é¢**å®æ—¶**ä¼ è¾“åˆ°äº‘ç«¯è¿›è¡Œå¤„ç†ï¼Œ
        å¹¶å°†ç»“æœ**å®æ—¶**è¿”å›æ˜¾ç¤ºã€‚æ‚¨å¯ä»¥é€šè¿‡ä¾§è¾¹æ çš„æ»‘å—å®æ—¶è°ƒæ•´æ£€æµ‹ç½®ä¿¡åº¦ã€‚
        """)
        
        # åˆ›å»º PoseDetectionTransformer çš„å®ä¾‹
        pose_transformer = PoseDetectionTransformer()
        # åˆå§‹è®¾ç½®ç½®ä¿¡åº¦
        pose_transformer.set_conf_threshold(conf_threshold)

        # é…ç½® WebRTC
        rtc_configuration = RTCConfiguration({
            "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
        })

        # ä½¿ç”¨ webrtc_streamer ç»„ä»¶å¯åŠ¨å®æ—¶æµ
        webrtc_ctx = webrtc_streamer(
            key="pose-detection",
            video_transformer_factory=lambda: pose_transformer,
            rtc_configuration=rtc_configuration,
            media_stream_constraints={"video": True, "audio": False},
            async_transform=True,
        )

        # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ä¸€ä¸ªç©ºçš„å ä½ç¬¦æ¥åŠ¨æ€æ›´æ–°ç½®ä¿¡åº¦
        # è¿™ä¸ªå ä½ç¬¦ä¸ä¼šæ˜¾ç¤ºä»»ä½•å†…å®¹ï¼Œä½†ä¼šåœ¨æ¯æ¬¡ç½®ä¿¡åº¦å˜åŒ–æ—¶è§¦å‘UIæ›´æ–°
        status_placeholder = st.empty()
        
        # å¦‚æœ WebRTC è¿æ¥å·²å»ºç«‹
        if webrtc_ctx.state.playing:
            # æŒç»­æ£€æŸ¥ç½®ä¿¡åº¦æ»‘å—æ˜¯å¦æœ‰å˜åŒ–
            if st.session_state.conf_threshold != conf_threshold:
                # æ›´æ–°å¤„ç†å™¨ä¸­çš„ç½®ä¿¡åº¦
                pose_transformer.set_conf_threshold(conf_threshold)
                # æ›´æ–° session_state ä»¥é¿å…é‡å¤è§¦å‘
                st.session_state.conf_threshold = conf_threshold
                
                # åœ¨å ä½ç¬¦ä¸­çŸ­æš‚æ˜¾ç¤ºä¸€ä¸ªæ›´æ–°æç¤ºï¼Œç„¶åç«‹å³æ¸…ç©º
                with status_placeholder:
                    st.success("ç½®ä¿¡åº¦å·²æ›´æ–°ï¼")
                    time.sleep(1)
                status_placeholder.empty()

else:
    st.error("ç”±äºæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåº”ç”¨æ— æ³•æ­£å¸¸è¿è¡Œã€‚è¯·æ£€æŸ¥äº‘ç«¯ç¯å¢ƒçš„ç½‘ç»œè¿æ¥å’Œé…ç½®ã€‚")