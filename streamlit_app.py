import streamlit as st
import cv2
import tempfile
from ultralytics import YOLO
import numpy as np
import time

# --- å…¨å±€è®¾ç½®å’Œè¡¥ä¸ ---

# 1. è§£å†³ OpenCV "The function is not implemented" é”™è¯¯
# å°† cv2.destroyAllWindows æ›¿æ¢ä¸ºä¸€ä¸ªç©ºæ“ä½œï¼Œå› ä¸ºæˆ‘ä»¬ä¸éœ€è¦å®ƒ
original_destroy_all_windows = cv2.destroyAllWindows
cv2.destroyAllWindows = lambda: None

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLO11 äººä½“å§¿æ€ä¼°è®¡",
    page_icon="ğŸ‘¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- è¾…åŠ©å‡½æ•° ---

def get_available_cameras(max_checks=10):
    """
    æ£€æµ‹å¹¶è¿”å›ç³»ç»Ÿä¸Šæ‰€æœ‰å¯ç”¨çš„æ‘„åƒå¤´ç´¢å¼•åˆ—è¡¨ã€‚
    """
    available_cameras = []
    for i in range(max_checks):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            available_cameras.append(i)
            cap.release()
        # çŸ­æš‚å»¶è¿Ÿï¼Œé˜²æ­¢æŸäº›æ‘„åƒå¤´åˆå§‹åŒ–è¿‡æ…¢
        time.sleep(0.05)
    return available_cameras

# --- æ¨¡å‹åŠ è½½ ---

@st.cache_resource
def load_model():
    """åŠ è½½ YOLO11 å§¿æ€æ¨¡å‹ (ä½¿ç”¨è½»é‡çº§çš„ n ç‰ˆæœ¬ä»¥æé«˜é€Ÿåº¦)"""
    try:
        model = YOLO('yolo11n-pose.pt')
        st.success("âœ… YOLO11 å§¿æ€æ¨¡å‹å·²æˆåŠŸåŠ è½½ï¼")
        return model
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None

# --- UI å¸ƒå±€ ---

# ä¾§è¾¹æ 
with st.sidebar:
    st.title('ğŸ‘¤ YOLO11 äººä½“å§¿æ€ä¼°è®¡')
    st.markdown("""
    è¿™ä¸ªåº”ç”¨ä½¿ç”¨ Ultralytics YOLO11 æ¨¡å‹è¿›è¡Œå®æ—¶äººä½“å§¿æ€ä¼°è®¡ã€‚
    æ”¯æŒå›¾ç‰‡ã€è§†é¢‘ä¸Šä¼ å’Œæ‘„åƒå¤´å®æ—¶æ£€æµ‹ã€‚
    """)
    st.divider()

    # 1. é€‰æ‹©è¾“å…¥æº
    source = st.selectbox("è¯·é€‰æ‹©è¾“å…¥æº", ["å›¾ç‰‡", "è§†é¢‘", "æ‘„åƒå¤´"])
    
    # 2. æ ¹æ®è¾“å…¥æºæ˜¾ç¤ºä¸åŒçš„é…ç½®
    conf_threshold = st.slider("æ£€æµ‹ç½®ä¿¡åº¦", 0.0, 1.0, 0.5, 0.05)
    
    camera_index = 0
    if source == "æ‘„åƒå¤´":
        available_cameras = get_available_cameras()
        if not available_cameras:
            st.warning("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨çš„æ‘„åƒå¤´ã€‚è¯·ç¡®ä¿æ‘„åƒå¤´å·²æ­£ç¡®è¿æ¥ã€‚")
        else:
            camera_index = st.selectbox("é€‰æ‹©æ‘„åƒå¤´", available_cameras)
    
    st.divider()
    st.markdown("Â© 2024 Streamlit & YOLO11")

# ä¸»é¡µé¢
st.title("YOLO11 äººä½“å§¿æ€ä¼°è®¡æ¼”ç¤º")
model = load_model()

# --- æ ¸å¿ƒé€»è¾‘å¤„ç† ---

if model is not None:
    if source == "å›¾ç‰‡":
        st.subheader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œå§¿æ€ä¼°è®¡")
        uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            col1, col2 = st.columns(2)
            
            # æ˜¾ç¤ºåŸå§‹å›¾ç‰‡
            with col1:
                st.markdown("### åŸå§‹å›¾ç‰‡")
                file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
                img = cv2.imdecode(file_bytes, 1)
                st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), use_column_width=True)
            
            # æ£€æµ‹å¹¶æ˜¾ç¤ºç»“æœ
            with col2:
                st.markdown("### å§¿æ€ä¼°è®¡ç»“æœ")
                if st.button("å¼€å§‹æ£€æµ‹"):
                    with st.spinner("æ­£åœ¨æ£€æµ‹å§¿æ€..."):
                        results = model(img, conf=conf_threshold)
                        annotated_img = results[0].plot()
                        st.image(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB), use_column_width=True)

    elif source == "è§†é¢‘":
        st.subheader("ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è¿›è¡Œå§¿æ€ä¼°è®¡")
        uploaded_file = st.file_uploader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘", type=["mp4", "mov", "avi", "mkv"])
        
        if uploaded_file is not None:
            # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(uploaded_file.read())
            
            cap = cv2.VideoCapture(tfile.name)
            if not cap.isOpened():
                st.error("âŒ æ— æ³•æ‰“å¼€ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶ã€‚")
            else:
                fps = int(cap.get(cv2.CAP_PROP_FPS))
                width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                
                st.write(f"ğŸ“Š è§†é¢‘å±æ€§: {width}x{height}, {fps} FPS, æ€»å¸§æ•°: {total_frames}")
                
                if st.button("å¼€å§‹å¤„ç†è§†é¢‘"):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    output_filename = "output_video.mp4"
                    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
                    out = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))
                    
                    with st.spinner("ğŸ¬ æ­£åœ¨å¤„ç†è§†é¢‘ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                        for frame_count in range(total_frames):
                            ret, frame = cap.read()
                            if not ret:
                                break
                                
                            results = model(frame, conf=conf_threshold)
                            annotated_frame = results[0].plot()
                            out.write(annotated_frame)
                            
                            progress = (frame_count + 1) / total_frames
                            progress_bar.progress(progress)
                            status_text.text(f"å¤„ç†è¿›åº¦: {frame_count + 1}/{total_frames} ({progress:.1%})")
                    
                    cap.release()
                    out.release()
                    progress_bar.empty()
                    status_text.empty()
                    
                    st.success("âœ… è§†é¢‘å¤„ç†å®Œæˆï¼")
                    
                    with open(output_filename, 'rb') as f:
                        st.download_button(
                            label='ğŸ“¥ ä¸‹è½½å¤„ç†åçš„è§†é¢‘',
                            data=f,
                            file_name=output_filename,
                            mime='video/mp4'
                        )

    elif source == "æ‘„åƒå¤´":
        st.subheader("ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶å§¿æ€ä¼°è®¡")
        
        # åˆ›å»ºä¸¤ä¸ªåˆ—ï¼Œä¸€ä¸ªç”¨äºæ˜¾ç¤ºç”»é¢ï¼Œä¸€ä¸ªç”¨äºæ§åˆ¶
        col1, col2 = st.columns([3, 1])
        
        with col2:
            st.markdown("### æ§åˆ¶")
            start_button = st.button("â–¶ï¸ å¼€å§‹")
            stop_button = st.button("â¹ï¸ åœæ­¢")
        
        with col1:
            frame_placeholder = st.empty()
            status_placeholder = st.empty()
        
        is_running = False
        cap = None
        
        if start_button:
            is_running = True
            # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ‘„åƒå¤´ç´¢å¼•
            cap = cv2.VideoCapture(camera_index)
            if not cap.isOpened():
                st.error(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ (ç´¢å¼•: {camera_index})ã€‚è¯·æ£€æŸ¥æ‘„åƒå¤´æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨æˆ–å°è¯•å…¶ä»–ç´¢å¼•ã€‚")
                is_running = False
            
            # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡ï¼ˆå¯é€‰ï¼Œæ ¹æ®ä½ çš„ç¡¬ä»¶è°ƒæ•´ï¼‰
            cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
            cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)

        while is_running:
            ret, frame = cap.read()
            if not ret:
                status_placeholder.error("âš ï¸ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢ã€‚")
                break
            
            # è¿›è¡Œå§¿æ€æ£€æµ‹
            results = model(frame, conf=conf_threshold)
            annotated_frame = results[0].plot()
            
            # æ˜¾ç¤ºç”»é¢
            frame_placeholder.image(annotated_frame, channels="BGR", use_column_width=True)
            status_placeholder.markdown("ğŸŸ¢ å®æ—¶æ£€æµ‹ä¸­...")
            
            # æ£€æŸ¥æ˜¯å¦æŒ‰ä¸‹åœæ­¢æŒ‰é’®
            if stop_button:
                is_running = False
                break
        
        if cap is not None:
            cap.release()
        
        if stop_button or not is_running:
            frame_placeholder.empty()
            status_placeholder.markdown("â¹ï¸ æ£€æµ‹å·²åœæ­¢ã€‚")

else:
    st.error("ç”±äºæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œåº”ç”¨æ— æ³•æ­£å¸¸è¿è¡Œã€‚è¯·æ£€æŸ¥ä½ çš„ç½‘ç»œè¿æ¥å’Œç¯å¢ƒé…ç½®ã€‚")