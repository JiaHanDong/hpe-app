import streamlit as st
import cv2
import tempfile
from ultralytics import YOLO
import numpy as np

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLO11 äººä½“å§¿æ€ä¼°è®¡",
    page_icon="ğŸ‘¤",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åœ¨ä¾§è¾¹æ æ·»åŠ æ ‡é¢˜å’Œè¯´æ˜
with st.sidebar:
    st.title('ğŸ‘¤ YOLO11 äººä½“å§¿æ€ä¼°è®¡')
    st.markdown("""
    è¿™ä¸ªåº”ç”¨ä½¿ç”¨ Ultralytics YOLO11 æ¨¡å‹æ¥è¿›è¡Œå®æ—¶äººä½“å§¿æ€ä¼°è®¡ã€‚
    æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼ä¸Šä¼ å†…å®¹ï¼š
    - ä¸Šä¼ ä¸€å¼ å›¾ç‰‡
    - ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶
    - ä½¿ç”¨æ‚¨çš„æ‘„åƒå¤´è¿›è¡Œå®æ—¶æ£€æµ‹
    """)
    
    # é€‰æ‹©è¾“å…¥æº
    source = st.selectbox("é€‰æ‹©è¾“å…¥æº", ["å›¾ç‰‡", "è§†é¢‘", "æ‘„åƒå¤´"])
    
    # ç½®ä¿¡åº¦æ»‘å—
    confidence = st.slider("æ£€æµ‹ç½®ä¿¡åº¦", 0.0, 1.0, 0.5, 0.05)
    
    st.markdown("---")
    st.markdown("Â© 2024 Streamlit & YOLO11")

# ä¸»é¡µé¢æ ‡é¢˜
st.title("YOLO11 äººä½“å§¿æ€ä¼°è®¡æ¼”ç¤º")

# åŠ è½½ YOLO11 å§¿æ€æ¨¡å‹
@st.cache_resource
def load_model():
    """åŠ è½½ YOLO11 å§¿æ€æ¨¡å‹"""
    model = YOLO('yolo11n-pose.pt')
    return model

model = load_model()
st.success("YOLO11 å§¿æ€æ¨¡å‹å·²æˆåŠŸåŠ è½½ï¼")

# æ ¹æ®é€‰æ‹©çš„è¾“å…¥æºè¿›è¡Œå¤„ç†
if source == "å›¾ç‰‡":
    st.subheader("ä¸Šä¼ ä¸€å¼ å›¾ç‰‡è¿›è¡Œå§¿æ€ä¼°è®¡")
    uploaded_file = st.file_uploader("é€‰æ‹©ä¸€å¼ å›¾ç‰‡", type=["jpg", "jpeg", "png"])
    
    if uploaded_file is not None:
        # å°†ä¸Šä¼ çš„æ–‡ä»¶è½¬æ¢ä¸º OpenCV æ ¼å¼
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        img = cv2.imdecode(file_bytes, 1)
        
        # åœ¨é¡µé¢ä¸Šæ˜¾ç¤ºåŸå§‹å›¾ç‰‡
        st.subheader("åŸå§‹å›¾ç‰‡")
        st.image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB), use_column_width=True)
        
        # è¿›è¡Œå§¿æ€æ£€æµ‹
        if st.button("å¼€å§‹æ£€æµ‹"):
            with st.spinner("æ­£åœ¨æ£€æµ‹å§¿æ€..."):
                results = model(img, conf=confidence)
                
                # ç»˜åˆ¶æ£€æµ‹ç»“æœ
                annotated_img = results[0].plot()
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                st.subheader("å§¿æ€ä¼°è®¡ç»“æœ")
                st.image(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB), use_column_width=True)

elif source == "è§†é¢‘":
    st.subheader("ä¸Šä¼ ä¸€ä¸ªè§†é¢‘æ–‡ä»¶è¿›è¡Œå§¿æ€ä¼°è®¡")
    uploaded_file = st.file_uploader("é€‰æ‹©ä¸€ä¸ªè§†é¢‘", type=["mp4", "mov", "avi", "mkv"])
    
    if uploaded_file is not None:
        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_file.read())
        
        # æ‰“å¼€è§†é¢‘æ–‡ä»¶
        cap = cv2.VideoCapture(tfile.name)
        
        # è·å–è§†é¢‘å±æ€§
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        st.write(f"è§†é¢‘å±æ€§: {width}x{height}, {fps} FPS, æ€»å¸§æ•°: {total_frames}")
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
        output_filename = "output_video.mp4"
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_filename, fourcc, fps, (width, height))
        
        # å¤„ç†è§†é¢‘
        if st.button("å¼€å§‹å¤„ç†è§†é¢‘"):
            progress_bar = st.progress(0)
            frame_count = 0
            
            with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´..."):
                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break
                    
                    # è¿›è¡Œå§¿æ€æ£€æµ‹
                    results = model(frame, conf=confidence)
                    annotated_frame = results[0].plot()
                    
                    # å†™å…¥å¤„ç†åçš„å¸§
                    out.write(annotated_frame)
                    
                    frame_count += 1
                    progress = frame_count / total_frames
                    progress_bar.progress(progress)
            
            # é‡Šæ”¾èµ„æº
            cap.release()
            out.release()
            cv2.destroyAllWindows()
            
            st.success("è§†é¢‘å¤„ç†å®Œæˆï¼")
            
            # æä¾›ä¸‹è½½é“¾æ¥
            with open(output_filename, 'rb') as f:
                st.download_button('ä¸‹è½½å¤„ç†åçš„è§†é¢‘', f, file_name=output_filename)

elif source == "æ‘„åƒå¤´":
    st.subheader("ä½¿ç”¨æ‘„åƒå¤´è¿›è¡Œå®æ—¶å§¿æ€ä¼°è®¡")
    
    # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦æ¥æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢
    frame_placeholder = st.empty()
    
    # åˆ›å»ºä¸€ä¸ªåœæ­¢æŒ‰é’®
    stop_button_pressed = st.button("åœæ­¢")
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
    
    # è®¾ç½®æ‘„åƒå¤´åˆ†è¾¨ç‡ï¼ˆå¯é€‰ï¼‰
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
    
    while not stop_button_pressed:
        ret, frame = cap.read()
        if not ret:
            st.error("æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
            break
        
        # è¿›è¡Œå§¿æ€æ£€æµ‹
        results = model(frame, conf=confidence)
        annotated_frame = results[0].plot()
        
        # æ˜¾ç¤ºç”»é¢
        frame_placeholder.image(annotated_frame, channels="BGR", use_column_width=True)
    
    # é‡Šæ”¾æ‘„åƒå¤´èµ„æº
    cap.release()
    cv2.destroyAllWindows()
    frame_placeholder.empty()
    st.write("æ‘„åƒå¤´å·²åœæ­¢")